---
title: "MADR_rlasso"
output: html_document
date: "2025-03-09"
---

# Description of coding file
This file details the process of generation of the benchmark models (rLASSO and MADR) from the paper. This file can has 2 main chunks to note:

(1) Functions involved to run the rLASSO, Adaptive LASSO, MADR and GLiDeR models are included here.
(2) MC Simulation function is denoted by mc_simulation function to generate 100 different estimations of ATE

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
packages = c("MASS", "glmnet", "boot", 
             "randomForest", "hdm", "caret", 
              "tidyverse", "doParallel", "foreach")

# Function to check, install if needed, and load libraries
install_and_load = function(pkg) {
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg, dependencies = TRUE)
    library(pkg, character.only = TRUE)
  }
}

# Apply function to all packages
sapply(packages, install_and_load)
```

# Relevant Model Functions

```{r}
# Load all GLiDeR functions
source("glider_fn.R")
source("data_sim_fn.R")

# Splitting function to split dataframe into treatment, outcome and X covariates
component_splitter = function(df){
  treatment = df$treatment
  outcome = df$outcome
  X_df = as.matrix(df %>% dplyr::select(-c(treatment, outcome)))
  return(list(treatment = treatment, outcome = outcome, X_df = X_df))
}

# ----- ## MODEL 1: SATURATED MODEL ## -----

saturated_model = function(dataframe){
  D = component_splitter(dataframe)[['treatment']]   # Treatment variable (D)
  X = component_splitter(dataframe)[['X_df']]        # Covariates (X)
  Y = component_splitter(dataframe)[['outcome']]     # Outcome variable (Y)
  
  # STEP 1: Fit the treatment model (propensity score estimation)
  treatment_model = glm(D ~ X, data = dataframe, family = binomial)
  pi_hat = predict(treatment_model, type = "response", newdata = dataframe)  # Propensity scores π(V;γ)
  
  # STEP 2: Fit outcome models separately for treated and control groups
  outcome_model_treat = lm(outcome ~ ., data = dataframe[D == 1, ])  # μ(1, X)
  outcome_model_control = lm(outcome ~ ., data = dataframe[D == 0, ]) # μ(0, X)
  
  mu_hat_1 = predict(outcome_model_treat, newdata = dataframe)  
  mu_hat_0 = predict(outcome_model_control, newdata = dataframe)
  
  # STEP 3: Compute the doubly robust estimator
  n = nrow(dataframe)
  
  # Formula in paper
  dr_estimate = mean(((D * Y) / pi_hat) - ((1 - D) * Y / (1 - pi_hat)) - 
                       ((D - pi_hat) / pi_hat) * mu_hat_1 - 
                       ((D - pi_hat) / (1 - pi_hat)) * mu_hat_0)
  final_lst = list(ate_est = dr_estimate, 
                   treatment_var = NA,
                   outcome_var = NA)
  return(final_lst)
}

#----## MODEL 2: REGULARISED LASSO ## ------

rlasso_model = function(dataframe){
  D = component_splitter(dataframe)[['treatment']]   # Treatment variable (D)
  X = component_splitter(dataframe)[['X_df']]        # Covariates (X)
  Y = component_splitter(dataframe)[['outcome']]     # Outcome variable (Y)
  
  ## Step 1: Standardising Outcome and X before variable selection ##
  Xstand = t(t(X - matrix(rep(apply(X, 2, mean), nrow(X)), nrow(X), byrow = TRUE)) *
              (1 / apply(X, 2, sd)))
  Ystand = Y / sd(Y)
  
  ## Step 2: Use rlasso to select covariates for both treatment (propensity score) and outcome models ##
  # 2a: Propensity score model (D ~ X)
  ps_model = rlasso(D ~ Xstand, post = TRUE)
  ps_selected_covariates = coef(ps_model)  # Get the selected covariates for the treatment model
  selected_ps_covariates = ps_selected_covariates[ps_selected_covariates != 0]
  selected_ps_covariate_names = names(selected_ps_covariates)
  # Remove intercept
  selected_ps_covariate_names = selected_ps_covariate_names[selected_ps_covariate_names != "(Intercept)"]  
  
  # 2b: Outcome model (Y ~ X + D)
  outcome_model = rlasso(Ystand ~ Xstand + D, post = TRUE)
  outcome_selected_covariates = coef(outcome_model)  # Get the selected covariates for the outcome model
  selected_outcome_covariates = outcome_selected_covariates[outcome_selected_covariates != 0]
  selected_outcome_covariate_names = names(selected_outcome_covariates)
  
  ## Step 3: Estimate the Propensity Scores (Phat) using the propensity score model ##
  selected_outcome_covariate_names = gsub("Xstand", "", selected_outcome_covariate_names)  # Remove "Xstand"
  selected_outcome_covariate_names = selected_outcome_covariate_names[!(selected_outcome_covariate_names %in% c("(Intercept)", "D"))]

  # Extract coefficients for the treatment model
  beta_trt = ps_selected_covariates[-1]  # Exclude the intercept term
  intercept_trt = ps_selected_covariates[1]  # Intercept for the treatment model
  
  # Compute propensity scores with logistic model
  Phat = exp(intercept_trt + Xstand %*% beta_trt) / (1 + exp(intercept_trt + Xstand %*% beta_trt))
  
  ## Step 4: Estimate the Outcome Model predictions (Yhat0 and Yhat1) ##
  
  # Extract of coefficients for outcome model
  beta_outcome = outcome_selected_covariates[-1]  # Exclude the intercept term
  beta_outcome = beta_outcome[-which(names(beta_outcome) == "D")] # Remove D from beta vector

  intercept_outcome = outcome_selected_covariates[1]  # Intercept for the outcome model
  beta_a = outcome_selected_covariates[length(outcome_selected_covariates)]  # Treatment effect coefficient
  
  # Predicted outcomes for no treatment (Yhat0) and treatment (Yhat1)
  Yhat0 = (rep(intercept_outcome, nrow(Xstand)) + Xstand %*% beta_outcome) * sd(Y)  # Yhat0 for no treatment
  Yhat1 = (rep(intercept_outcome, nrow(Xstand)) + beta_a + Xstand %*% beta_outcome) * sd(Y)  # Yhat1 for treatment
  
  ## Step 5: Calculate the Counterfactual Outcomes (DR Estimator) ##
  muhat1 = (D * Y / Phat) - ((D - Phat) / Phat) * Yhat1
  muhat0 = (((1 - D) * Y) / (1 - Phat)) + (((D - Phat) / (1 - Phat)) * Yhat0)
  
  ## Step 6: Compute the Doubly Robust Estimator for the Average Treatment Effect (ATE), and show the number of variables that have been selected ##
  drest = mean(muhat1 - muhat0)
  final_lst = list(ate_est = drest, 
                   treatment_var = paste(selected_ps_covariate_names, collapse = ", "),
                   outcome_var = paste(selected_outcome_covariate_names, collapse = ", "))
  return(final_lst)
}

#----- ## MODEL 3: MADR MODEL BY CEFALU (2016) ## -----

madr_model = function(dataframe) {
  
  D = component_splitter(dataframe)[['treatment']]   # Treatment variable (D)
  X = component_splitter(dataframe)[['X_df']]        # Covariates (X)
  Y = component_splitter(dataframe)[['outcome']]     # Outcome variable (Y)
  X_standardized = scale(X)
  
  # Step 1: Fit treatment models (logit and probit) for propensity score estimation
  logit_model = glm(D ~ X_standardized, family = binomial(link = "logit"))
  probit_model = glm(D ~ X_standardized, family = binomial(link = "probit"))
  print('fitted')
  # Propensity scores from both models
  ps_logit = predict(logit_model, type = "response")  # Propensity scores from logit
  ps_probit = predict(probit_model, type = "response") # Propensity scores from probit
  
  df_stan = as.data.frame(cbind(Y, X_standardized, D))

  # Step 2: Fit outcome models (GAM and Linear regression) for treated and control groups
  lm_model_treated = lm(Y~., data = df_stan, subset = (D == 1))  # Linear for treated
  lm_model_untreated = lm(Y~., data = df_stan, subset = (D == 0))  # Linear for untreated
  
  rf_model_treated = randomForest(Y~., data = df_stan, subset = (D == 1)) # RF regression for outcome
  rf_model_untreated = randomForest(Y~., data = df_stan, subset = (D == 0)) # RF regression for outcome
  print("models fitted")
  
  # Predictions for outcome models
  lm_predictions_treated = predict(lm_model_treated, type = "response", newdata = df_stan, method = "ML")
  lm_predictions_untreated = predict(lm_model_untreated, type = "response", newdata = df_stan, method = "ML")
  
  rf_predictions_treated = predict(rf_model_treated, type = "response", newdata = df_stan)
  rf_predictions_untreated = predict(rf_model_untreated, type = "response", newdata = df_stan)
  
  compute_double_robust = function(Y, D, e, m1, m0) {
    # Y: Observed outcomes
    # D: Treatment indicator (0 or 1)
    # e: Estimated propensity score (probability of treatment)
    # m1: Estimated outcome for treated group (X = 1)
    # m0: Estimated outcome for control group (X = 0)
    
    # Calculate the double robust estimator
    
    dr_estimate = mean(((D * Y) / e) - ((1 - D) * Y / (1 - e)) - 
                       ((D - e) / e) * m1 - 
                       ((D - e) / (1 - e)) * m0)
    return(dr_estimate)
  }
  
  ate_rf_logit = compute_double_robust(Y, D, ps_logit, 
                                        rf_predictions_treated, rf_predictions_untreated)
  
  ate_lm_logit = compute_double_robust(Y, D, ps_logit, 
                                        lm_predictions_treated, lm_predictions_untreated)
  
  ate_rf_probit = compute_double_robust(Y, D, ps_probit, 
                                        rf_predictions_treated, rf_predictions_untreated)
  
  ate_lm_probit = compute_double_robust(Y, D, ps_probit, 
                                        lm_predictions_treated, lm_predictions_untreated)
  # Averaging the ATEs from both treatment models (logit and probit)
  ate_madr = (ate_lm_logit + ate_rf_logit + ate_lm_probit + ate_rf_probit) / 4

  return(list(ate_est = ate_madr, 
              treatment_var = NA,
              outcome_var = NA))
}

#----- ## MODEL 4: GLIDER FUNCTION ## -----

glider_model = function(dataframe){
  D = component_splitter(dataframe)[['treatment']]   # Treatment variable (D)
  X = component_splitter(dataframe)[['X_df']]        # Covariates (X)
  Y = component_splitter(dataframe)[['outcome']]     # Outcome variable (Y)
  params = GLiDeR(X, Y, D, lambda = NULL)
  alpha_indices = which(params$alpha != 0)
  gamma_indices = which(params$gamma != 0)
  # Add "X" to each index number and join them with ", "
  treatment_var = paste0("X", alpha_indices, collapse = ", ")
  outcome_var = paste0("X", gamma_indices, collapse = ", ")
  
  # Create the final list
  result_list = list(
    ate_est = params$delta,
    treatment_var = treatment_var,
    outcome_var = outcome_var
  )
  return(result_list)
}

# ----- ## MODEL 5: ADAPTIVE LASSO ## -----

adaptive_lasso_model = function(dataframe){
  D = component_splitter(dataframe)[['treatment']]   # Treatment variable (D)
  X = component_splitter(dataframe)[['X_df']]        # Covariates (X)
  Y = component_splitter(dataframe)[['outcome']]     # Outcome variable (Y)
  
  ## STEP 1: Generation of initial estimates of the coefficients
  ols_model = lm(Y ~ X)  # Fit OLS model
  beta_ols = coef(ols_model)[-1]  # Exclude intercept
  weights = 1 / abs(beta_ols)  # Adaptive weights
  weights[is.infinite(weights)] = max(weights[is.finite(weights)])  # Avoid Inf
  weights[is.na(weights)] = min(weights[is.finite(weights)])  # Avoid Inf
  cvfit = cv.glmnet(X, Y, alpha = 1, penalty.factor = weights, nfolds = 10)
  
  # Extraction of the best lambda
  lambda_opt = cvfit$lambda.min
  
  ## STEP 2: Selection of variables based on algorithm ##
  # Fit final model using best lambda
  adaptive_lasso = glmnet(X, Y, alpha = 1, lambda = lambda_opt, penalty.factor = weights)
  selected_covariates = which(coef(adaptive_lasso)[-1] != 0)  # Exclude intercept

  ## Step 3: Directly extract ATE ##
  
  X_selected = X[, selected_covariates, drop = FALSE]  # Keep only selected variables
  if (length(selected_covariates) == 0) {
    # No covariates selected, use only D in the final model
    final_model = lm(Y ~ D)
  } else {
    X_selected = X[, selected_covariates, drop = FALSE]  # Keep only selected variables
    final_model = lm(Y ~ D + X_selected)  # Refit outcome model
  }
  
  ate_est = coef(final_model)["D"]
  joined_covariates = paste(paste0("X", selected_covariates), collapse = ", ")
  return(list(ate_est = ate_est, 
              treatment_var = NA,
              outcome_var = joined_covariates))
}

# ----- ## MODEL 6: BACKWARD SELECTION ## -----

backward_selection_model = function(dataframe){
  D = component_splitter(dataframe)[['treatment']]   # Treatment variable (D)
  X = component_splitter(dataframe)[['X_df']]        # Covariates (X)
  Y = component_splitter(dataframe)[['outcome']]     # Outcome variable (Y)
  
  # Create dataframes for modeling
  treat_df = dataframe[D == 1, ]
  control_df = dataframe[D == 0, ]
  
  # STEP 1: Backward selection for treatment model
  # Start with full model
  full_treatment_model = glm(treatment ~ ., data = dataframe %>% dplyr::select(-outcome), family = binomial)
  
  # Handle step with tryCatch to avoid AIC -infinity issues
  treatment_model = tryCatch({
    step(full_treatment_model, direction = "backward", trace = 0)
  }, error = function(e) {
    # If step fails, use the intercept-only model
    message("Treatment model selection failed, using intercept-only model")
    glm(treatment ~ 1, data = dataframe, family = binomial)
  })
  
  # Record selected variables
  treatment_formula = formula(treatment_model)
  treatment_var = attr(terms(treatment_formula), "term.labels")
  if(length(treatment_var) == 0) {
    treatment_var = NA  # Handle case where no variables are selected
  }
  
  # Get propensity scores
  pi_hat = predict(treatment_model, type = "response", newdata = dataframe)
  # Trim propensity scores to avoid extreme values
  pi_hat = pmax(pmin(pi_hat, 0.99), 0.01)
  
  # STEP 2: Backward selection for outcome models
  # Treated group
  full_outcome_treat = lm(outcome ~ ., data = treat_df %>% dplyr::select(-treatment))
  outcome_model_treat = tryCatch({
    step(full_outcome_treat, direction = "backward", trace = 0)
  }, error = function(e) {
    message("Treated outcome model selection failed, using intercept-only model")
    lm(outcome ~ 1, data = treat_df)
  })
  
  # Control group
  full_outcome_control = lm(outcome ~ ., data = control_df %>% dplyr::select(-treatment))
  outcome_model_control = tryCatch({
    step(full_outcome_control, direction = "backward", trace = 0)
  }, error = function(e) {
    message("Control outcome model selection failed, using intercept-only model")
    lm(outcome ~ 1, data = control_df)
  })
  
  # Record selected variables
  outcome_formula_treat = formula(outcome_model_treat)
  outcome_formula_control = formula(outcome_model_control)
  outcome_var_treat = attr(terms(outcome_formula_treat), "term.labels")
  outcome_var_control = attr(terms(outcome_formula_control), "term.labels")
  
  outcome_var = unique(c(outcome_var_treat, outcome_var_control))
  if(length(outcome_var) == 0) {
    outcome_var = NA  # Handle case where no variables are selected
  }
  
  # Generate predictions
  mu_hat_1 = predict(outcome_model_treat, newdata = dataframe)  
  mu_hat_0 = predict(outcome_model_control, newdata = dataframe)

  # Calculate doubly robust estimate
  dr_estimate = mean(((D * Y) / pi_hat) - ((1 - D) * Y / (1 - pi_hat)) - 
                    ((D - pi_hat) / pi_hat) * mu_hat_1 - 
                    ((D - pi_hat) / (1 - pi_hat)) * mu_hat_0)
  
  # Return results
  final_lst = list(ate_est = dr_estimate, 
                   treatment_var = treatment_var,
                   outcome_var = outcome_var)
  return(final_lst)
}

# ----- ## MODEL 7: SIS LASSO ## -----
sis_lasso_model = function(dataframe){
  D = component_splitter(dataframe)[['treatment']]   # Treatment variable (D)
  X = component_splitter(dataframe)[['X_df']]        # Covariates (X)
  Y = component_splitter(dataframe)[['outcome']]     # Outcome variable (Y)
  
  # Create dataframes for modeling
  full_df = as.data.frame(cbind(X, treatment = D, outcome = Y))
  treat_df = full_df[D == 1, ]
  control_df = full_df[D == 0, ]
  
  # STEP 1: SIS for treatment model
  # Calculate univariate correlations for screening
  p = ncol(X)
  treatment_cors = numeric(p)
  for (j in 1:p) {
    treatment_cors[j] = abs(cor(X[, j], D))
  }
  
  # Select top d variables (using sqrt(n) as a rule)
  d = min(ceiling(sqrt(nrow(full_df))), p)
  selected_vars_idx = order(treatment_cors, decreasing = TRUE)[1:d]
  selected_vars = colnames(X)[selected_vars_idx]
  
  # LASSO on selected variables for treatment model
  X_selected = X[, selected_vars_idx]
  cv_fit = cv.glmnet(X_selected, D, family = "binomial", alpha = 1)
  beta = as.vector(coef(cv_fit, s = "lambda.min"))[-1]  # exclude intercept
  
  # Get final selected variables after LASSO
  treatment_var = selected_vars[abs(beta) > 0]
  
  # Create formula for final model
  if (length(treatment_var) > 0) {
    treatment_formula = as.formula(paste("treatment ~", paste(treatment_var, collapse = " + ")))
    treatment_model = glm(treatment_formula, data = full_df, family = binomial)
  } else {
    treatment_model = glm(treatment ~ 1, data = full_df, family = binomial)
    treatment_var = NA
  }
  
  # Get propensity scores
  pi_hat = predict(treatment_model, type = "response", newdata = full_df)
  # Trim propensity scores to avoid extreme values
  pi_hat = pmax(pmin(pi_hat, 0.99), 0.01)
  
  # STEP 2: SIS for outcome models
  # Treated group
  treat_cors = numeric(p)
  for (j in 1:p) {
    treat_cors[j] = abs(cor(X[D == 1, j], Y[D == 1]))
  }
  
  # Select top d variables for treated
  d_treat = min(ceiling(sqrt(nrow(treat_df))), p)
  selected_treat_idx = order(treat_cors, decreasing = TRUE)[1:d_treat]
  selected_treat_vars = colnames(X)[selected_treat_idx]
  
  # LASSO on selected variables for treated outcome
  X_treat_selected = X[D == 1, selected_treat_idx]
  cv_treat = cv.glmnet(X_treat_selected, Y[D == 1], alpha = 1)
  beta_treat = as.vector(coef(cv_treat, s = "lambda.min"))[-1]  # exclude intercept
  
  # Get final selected variables for treated after LASSO
  outcome_var_treat = selected_treat_vars[abs(beta_treat) > 0]
  
  # Control group
  control_cors = numeric(p)
  for (j in 1:p) {
    control_cors[j] = abs(cor(X[D == 0, j], Y[D == 0]))
  }
  
  # Select top d variables for control
  d_control = min(ceiling(sqrt(nrow(control_df))), p)
  selected_control_idx = order(control_cors, decreasing = TRUE)[1:d_control]
  selected_control_vars = colnames(X)[selected_control_idx]
  
  # LASSO on selected variables for control outcome
  X_control_selected = X[D == 0, selected_control_idx]
  cv_control = cv.glmnet(X_control_selected, Y[D == 0], alpha = 1)
  beta_control = as.vector(coef(cv_control, s = "lambda.min"))[-1]  # exclude intercept
  
  # Get final selected variables for control after LASSO
  outcome_var_control = selected_control_vars[abs(beta_control) > 0]
  
  # Create formulas for final outcome models
  if (length(outcome_var_treat) > 0) {
    treat_formula = as.formula(paste("outcome ~", paste(outcome_var_treat, collapse = " + ")))
    outcome_model_treat = lm(treat_formula, data = treat_df)
  } else {
    outcome_model_treat = lm(outcome ~ 1, data = treat_df)
  }
  
  if (length(outcome_var_control) > 0) {
    control_formula = as.formula(paste("outcome ~", paste(outcome_var_control, collapse = " + ")))
    outcome_model_control = lm(control_formula, data = control_df)
  } else {
    outcome_model_control = lm(outcome ~ 1, data = control_df)
  }
  
  # Combine all selected outcome variables
  outcome_var = unique(c(outcome_var_treat, outcome_var_control))
  if (length(outcome_var) == 0) {
    outcome_var = NA
  }
  
  # Generate predictions
  mu_hat_1 = predict(outcome_model_treat, newdata = full_df)  
  mu_hat_0 = predict(outcome_model_control, newdata = full_df)

  # Calculate doubly robust estimate
  dr_estimate = mean(((D * Y) / pi_hat) - ((1 - D) * Y / (1 - pi_hat)) - 
                    ((D - pi_hat) / pi_hat) * mu_hat_1 - 
                    ((D - pi_hat) / (1 - pi_hat)) * mu_hat_0)
  
  # Return results
  final_lst = list(ate_est = dr_estimate, 
                   treatment_var = treatment_var,
                   outcome_var = outcome_var)
  return(final_lst)
}
```

# Running of Models under different scenarios
```{r}

num_cores = detectCores()-1
cl = makeCluster(num_cores)
registerDoParallel(cl)

mc_simulation_parallel = function(df_func, num_params, num_params_scene10, madr_bin = FALSE, total_sim) {
  df_final = data.frame(scenario = 1:13)
  if (madr_bin) {
    df_final = df_final[df_final$scenario != 10, ]
  }
  
  # Set up parallel backend
  num_cores = detectCores() - 1
  cl = makeCluster(num_cores)
  registerDoParallel(cl)
  results = foreach(sim_num = 1:total_sim, 
                    .combine = cbind, 
                    .packages = c("dplyr","MASS","glmnet","boot","randomForest","hdm","glmnet","caret"), 
                    .export = c("overall_scenario_generator", "df_func", "df_generator", "component_splitter",
                                "outgradient", "outgradient_scalar", "trtgradient", "trtgradient_scalar",
                                "negsumgrad", "negsumgrad_scalar", "algorithm1", "groupLassoAlgo",
                                "GLiDeR")) %dopar% {
    scenarios_lst = overall_scenario_generator(num_params = num_params, num_params_scene10 = num_params_scene10)
    ate_est_vec = numeric()
    
    for (scene_num in 1:13) {
      if (scene_num == 10 && madr_bin) {
        next
      }
      print(paste0("Scenario ", scene_num, " with ", num_params, " variables in progress..."))
      scenario_name = paste0("scenario_", scene_num)
      scenario_df = scenarios_lst[[scenario_name]]
      df_loop_lst = df_func(scenario_df)
      ate_est_vec = c(ate_est_vec, df_loop_lst$ate_est)
    }
    return(ate_est_vec)
  }
  
  stopCluster(cl) # Stop parallel backend
  
  colnames(results) = paste0("sim_", 1:total_sim)
  df_final = cbind(df_final, results)
  
  return(df_final)
}

models = c('rlasso','saturated','glider','adaptive_lasso','madr','backward_selection','sis_lasso')
# models = c('sis_lasso')
num_sim = 1000
num_params = 10
num_params_scene10 = 75

for (model_name in models){
  model_df_func = get(paste0(model_name, '_model'))
  
  # Always skip scenario 10 for backward_selection
  if(model_name == 'backward_selection' | model_name == "madr") {
    model_df = mc_simulation_parallel(model_df_func, 
                                     num_params = num_params, 
                                     num_params_scene10 = num_params_scene10, 
                                     madr_bin = TRUE,  # Skip scenario 10
                                     total_sim = num_sim)
  } else {
    model_df = mc_simulation_parallel(model_df_func, 
                                     num_params = num_params, 
                                     num_params_scene10 = num_params_scene10, 
                                     madr_bin = FALSE,  # Include all scenarios
                                     total_sim = num_sim)
  }
  # Save results
  new_file = paste0(model_name, '_df_', num_params, 'var_scene10_', num_params_scene10,'.rdata')
  assign(paste0(model_name, '_df_', num_params, 'var_scene10_', num_params_scene10), model_df)
  save(list = paste0(model_name, '_df_', num_params, 'var_scene10_', num_params_scene10), file = new_file)
  
  if (model_name == models[length(models)]){
    print("All Models Done!")
  } else {
    print(paste0(model_name, " Done - Moving on to next model..."))
  }
}

stopCluster(cl)
```


# Combination of Functions into a single list object
In this object, each element is labelled by its name. Each element is a dataframe consisting of the scenario number, and the 1000 simulated ATE computations obtained from the model itself.

```{r}
rm(list=ls())
models = c('saturated', 'rlasso', 'glider', 'adaptive_lasso', 'madr', 'backward_selection', 'sis_lasso')

models_df_compiler = function(model_lst, num_var, num_scene10_var){
  compiled_simulations_results = list()
  for (model_name in models){
    # Extract model's predictions
    load(paste0(model_name,"_df_", num_var,"var_scene10_", num_scene10_var,".rdata"))
    
    # Saving into list
    compiled_simulations_results[[model_name]] = get(paste0(model_name,"_df_", num_var,"var_scene10_", num_scene10_var))
  }
  compiled_name = paste0("overall_",num_var,"var_scene10_",num_scene10_var,"_simulations")
  assign(compiled_name,compiled_simulations_results)
  save(list=compiled_name,file=paste0(compiled_name,".rdata"))
  return(get(compiled_name))
}

# Saving model
overall_df = models_df_compiler(model_lst = models, num_var = 10, num_scene10_var = 75)

```

# Processing of results
Results are saved in a list object, and each element is denoted by its model name. 

For each model in the list, the following are shown:
1) Scenario Number
2) MC Bias
3) MC SD
4) Model MSE
5) Saturated Model MSE
6) MSE Ratio

```{r}
rm(list=ls())
results_processor = function(df, model_name){
  bias_name = paste0(model_name, "_bias_mc")
  sd_name = paste0(model_name, "_sd_mc")
  mse_name = paste0(model_name, "_mse_mc")
  df = df %>%
    mutate(
      across(starts_with("sim"), ~ case_when(
        . > 100  ~ 100,  # Replace large positive values
        . < -100 ~ -100, # Replace large negative values
        TRUE    ~ .  # Keep values within the range
      ))) %>%
    ungroup()
  df[[bias_name]] = rowMeans(select(df, starts_with("sim")), na.rm = TRUE) - 1
  df[[sd_name]] = apply(select(df, starts_with("sim")), 1, sd, na.rm = TRUE)
  df[[mse_name]] = rowMeans((select(df, starts_with("sim")) - 1)^2, na.rm = TRUE)
  df = df %>% select(scenario, bias_name, sd_name, mse_name)
  return(df)
}

# --- GENERATION OF MC BIAS, MC SD, MC MSE BASED ON ATE --- #

num_var = 5
scene10_num = 75
models = c('saturated', 'rlasso', 'glider', 'adaptive_lasso', 'madr', 'backward_selection', 'sis_lasso')
load("overall_10var_scene10_75_simulations.rdata")

overall_df_processing_fn = function(simulations_df, num_var, scene10_num, models_lst){
  
  # Store processed results in a list
  mc_ratio_lst = list()
  
  # Process the models
  for (model_name in models) {
    
    # Generation of MSE, MC bias, MC SD, MSE (for model itself)
    model_df = simulations_df[[model_name]]
    if (model_name == "backward_selection"|model_name == "madr"){
      model_df = as.data.frame(model_df)
      model_df = model_df %>% rename("scenario" = "df_final")
    }
    new_df = results_processor(model_df, model_name)
    new_name = paste0(model_name, "_processed_", num_var, "var_scene10_", scene10_num)
    assign(new_name, new_df)
    
    # Retrieve saturated model for MC ratio computation
    saturated_mse = get(paste0("saturated", "_processed_", num_var, "var_scene10_", scene10_num)) %>% 
      select(scenario, saturated_mse_mc)
    saturated_mse_noscene10 = get(paste0("saturated", "_processed_", num_var, "var_scene10_", scene10_num)) %>% 
      filter(scenario != 10) %>% 
      select(scenario, saturated_mse_mc)
    
    # For saturated models (those with MSE computations)
    if (model_name != "saturated") {
      mse_col_name = paste0(model_name, "_mse_mc")
      
      # Choose correct saturated dataset based on model type
      saturated_data = if (model_name %in% c("madr", "backward_selection")) {
        saturated_mse_noscene10
      } else {
        saturated_mse
      }
      
      # Process data to compute MSE ratio and store in processed_data
      mc_ratio_lst[[model_name]] = get(new_name) %>%
        left_join(saturated_data, by = "scenario") %>%
        mutate(mse_ratio = saturated_mse_mc / .data[[mse_col_name]])
    }
    print(paste0(model_name, " Done!"))
  }
  
  compiled_name = paste0("mcratio_",num_var,"var_scene10_",scene10_num)
  assign(compiled_name, mc_ratio_lst)
  save(list=compiled_name,file=paste0(compiled_name,".rdata"))
  return(get(compiled_name))
}

x = overall_df_processing_fn(overall_10var_scene10_75_simulations, num_var=10, scene10_num = 75, models_lst = models)

```
